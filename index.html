

<meta name="description" content="Kuofeng Gao's homepage">
<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
<title>Kuofeng Gao's Homepage</title>


<body>

<div id="layout-content" style="margin-top:25px">

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Kuofeng Gao &nbsp;</div>

				<h3>Fifth-year Ph.D. Student</h3>  
				<p>
					Room 1622, Information Building <br>
                    Tsinghua Shenzhen International Graduate School <br>
                    Shenzhen, Guangdong Province, China, 518055 <br>
					<br>
Email:  <a href="mailto:gkf21@mails.tsinghua.edu.cn">gkf21@mails.tsinghua.edu.cn</a> <br>

<br>
<a href="https://scholar.google.com/citations?user=0hVZ0woAAAAJ&hl=zh-CN">[Google Scholar]</a> <a href="https://github.com/KuofengGao">[Github]</a> 
					<br>
				</p>
			</td>
			<td>
				<img src="./files/gkf.jpg" border="0" width="150">
			</td>
		</tr><tr>
	</tr></tbody>
</table>
<h2>Biography</h2>
<p>
    I am currently pursuing my Ph.D. degree in Computer Science and Technology at <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, advised by Prof. <a href="https://scholar.google.com/citations?user=koAXTXgAAAAJ">Shu-Tao Xia</a>. 
    I was a research intern at Sea AI Lab from 2024 to 2025, advised by Dr. <a href="https://scholar.google.com/citations?user=wYDbtFsAAAAJ">Tianyu Pang</a> and Dr. <a href="https://scholar.google.com/citations?user=QOp7xW0AAAAJ">Chao Du</a>. 
    I was a research intern at Tencent Hunyuan Group, <a href="https://www.tencent.com/index.php/zh-cn/index.html">Tencent</a> from 2023 to 2024, advised by Dr. <a href="https://scholar.google.com/citations?user=VTrRNN4AAAAJ">Zhifeng Li</a> and Dr. <a href="https://scholar.google.com.hk/citations?user=AjxoEpIAAAAJ">Wei Liu</a>. 
    I obtained my Bachelor's degree in Computer Science from <a href="https://www.whu.edu.cn/">Wuhan University</a>, advised by Prof. <a href="https://scholar.google.com.hk/citations?user=0ox7zDkAAAAJ&hl=en">Zhibo Wang</a>.
</p>
<p>
    My research mainly focuses on Trustworthy ML and Responsible AI, especially adversarial learning and backdoor learning. Recently, I focus more on Trustworthy Large Foundation Models (e.g., LLMs and Diffusion Model).
</p>

<h2>Publications</h2> (* indicates equal contribution)
<h3>2025</h3>
<ul>
	<li>
        <a href='https://arxiv.org/abs/2505.19678'>Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs</a> <br>
        Hao Fang, Changle Zhou, Jiawei Kong, <strong><u>Kuofeng Gao</u></strong>, Bin Chen, Tao Liang, Guojun Ma, Shu-Tao Xia <br>
        Annual Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2025 <br>
        <a href="https://github.com/horizonsinzqs/QueryAttack">[code]</a>
        <a href="https://arxiv.org/abs/2505.19678">[arxiv]</a>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2505.15337'>Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors</a> <br>
        Hao Fang, Jiawei Kong, Tianqu Zhuang, Yixiang Qiu, <strong><u>Kuofeng Gao</u></strong>, Bin Chen, Shu-Tao Xia, Yaowei Wang, Min Zhang <br>
        Empirical Methods in Natural Language Processing <strong>(EMNLP)</strong>, 2025 <br>
        <a href="https://github.com/ffhibnese/CoPA_Contrastive_Paraphrase_Attacks">[code]</a>
        <a href="https://arxiv.org/abs/2505.15337">[arxiv]</a>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2502.09723'>Pre-training CLIP against Data Poisoning with Optimal Transport-based Matching and Alignment</a> <br>
        Tong Zhang*, <strong><u>Kuofeng Gao*</u></strong>, Jiawang Bai*, Leo Yu Zhang, Xin Yin, Zonghui Wang, Shouling Ji, Wenzhi CHEN <br>
        Empirical Methods in Natural Language Processing <strong>(EMNLP)</strong>, 2025 <br>
        <a href="https://github.com/horizonsinzqs/QueryAttack">[code]</a>
        <a href="https://arxiv.org/abs/2502.09723">[arxiv]</a>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2502.09723'>QueryAttack: Jailbreaking Aligned Large Language Models Using Structured Non-natural Query Language</a> <br>
        Qingsong Zou, Jingyu Xiao, Qing Li, Zhi Yan, Yuhang Wang, Li Xu, Wenxuan Wang, <strong><u>Kuofeng Gao</u></strong>, Ruoyu Li, Yong Jiang <br>
        Annual Meeting of the Association for Computational Linguistics <strong>(ACL-Findings)</strong>, 2025 <br>
        <a href="https://github.com/horizonsinzqs/QueryAttack">[code]</a>
        <a href="https://arxiv.org/abs/2502.09723">[arxiv]</a>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2506.15755'>VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service</a> <br>
        Xiasi Wang, Tianliang Yao, Simin Chen, Runqi Wang, Lei Ye, <strong><u>Kuofeng Gao</u></strong>, Yi Huang, Yuan Yao <br>
        Annual Meeting of the Association for Computational Linguistics <strong>(ACL)</strong>, 2025 <br>
        <a href="https://github.com/wangdaha1/VLMInferSlow">[code]</a>
        <a href="https://arxiv.org/abs/2506.15755">[arxiv]</a>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2412.05167'>Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models</a> <br>
        <strong><u>Kuofeng Gao</u></strong>, Shu-Tao Xia, Ke Xu, Philip Torr, Jindong Gu <br>
        Annual Meeting of the Association for Computational Linguistics <strong>(ACL)</strong>, 2025 <br>
        <a href="https://github.com/KuofengGao/ADU-Bench">[code]</a>
        <a href="https://arxiv.org/abs/2412.05167">[arxiv]</a>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2503.21824'>Protecting Your Video Content: Disrupting Automated Video-based LLM Annotations</a> <br>
        Haitong Liu*, <strong><u>Kuofeng Gao*</u></strong>, Yang Bai, Jinmin Li, Jinxiao Shan, Tao Dai, Shu-Tao Xia <br>
        IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2025 <br>
        <a href="https://github.com/ttthhl/Protecting_Your_Video_Content">[code]</a>
        <a href="https://arxiv.org/abs/2503.21824">[arxiv]</a>
    </li>
</ul>

<h3>2024</h3>
<ul>
	<li>
        <a href='https://mp.weixin.qq.com/s/KCWw9gBwUnzywyNW_K8-4A'>LLM Safety and Ethics (in Chinese)</a> <br>
        <strong><u>Kuofeng Gao</u></strong>, Linghui Zhu, Yuqi Tan, Sheng Yang, Yuang Peng, Wen Huang, Yiming Li, Shu-Tao Xia <br>
        Technical Report, 2024 <br>
        <a href="https://mp.weixin.qq.com/s/KCWw9gBwUnzywyNW_K8-4A">[arxiv]</a>
    </li>
	<li>
        <a href='https://ieeexplore.ieee.org/abstract/document/10745757/'>Pointncbw: Towards Dataset Ownership Verification for Point Clouds via Negative Clean-label Backdoor Watermark</a> <br>
        Cheng Wei, Yang Wang, <strong><u>Kuofeng Gao</u></strong>, Shuo Shao, Yiming Li, Zhibo Wang, Zhan Qin <br>
        IEEE Transactions on Information Forensics and Security <strong>(TIFS)</strong>, 2024 <br>
        <a href="https://github.com/weic0810/PointNCBW">[code]</a>
        <a href="https://ieeexplore.ieee.org/abstract/document/10745757/">[arxiv]</a>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2407.02411'>Video Watermarking: Safeguarding Your Video from (Unauthorized) Annotations by Video-based LLMs</a> <br>
        Jinmin Li, <strong><u>Kuofeng Gao</u></strong>, Yang Bai, Jingyun Zhang, Shu-Tao Xia <br>
        ICML 2024 Workshop on Trustworthy Multi-modal Foundation Models and AI Agents, 2024 <br>
        <a href="https://github.com/THU-Kingmin/VideoWatermarking">[code]</a>
        <a href="https://arxiv.org/abs/2407.02411">[arxiv]</a>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2405.10612'>Not All Prompts Are Secure: A Switchable Backdoor Attack Against Pre-trained Vision Transformers</a> <br>
        Sheng Yang, Jiawang Bai, <strong><u>Kuofeng Gao</u></strong>, Yong Yang, Yiming Li, Shu-Tao Xia <br>
        IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2024 <br>
        <a href="https://github.com/20000yshust/SWARM">[code]</a>
        <a href="https://arxiv.org/abs/2405.10612">[arxiv]</a>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2311.16194'>BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP</a> <br>
        Jiawang Bai*, <strong><u>Kuofeng Gao*</u></strong>,  Shaobo Min, Shu-Tao Xia, Zhifeng Li, Wei Liu <br>
        IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2024 <br>
        <a href="https://github.com/jiawangbai/BadCLIP">[code]</a>
        <a href="https://arxiv.org/abs/2311.16194">[arxiv]</a>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2405.09981'>Adversarial Robustness for Visual Grounding of Multimodal Large Language Models</a> <br>
        <strong><u>Kuofeng Gao</u></strong>, Yang Bai, Jiawang Bai, Yong Yang, Shu-Tao Xia <br>
        ICLR 2024 Workshop on Reliable and Responsible Foundation Models, 2024 <br>
        <a href="https://github.com/KuofengGao/MLLM-Grounding-Robustness">[code]</a>
        <a href="https://arxiv.org/abs/2405.09981">[arxiv]</a>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2401.11170'>Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images</a> <br>
        <strong><u>Kuofeng Gao</u></strong>, Yang Bai, Jindong Gu, Shu-Tao Xia, Philip Torr, Zhifeng Li, Wei Liu <br>
        International Conference on Learning Representations <strong>(ICLR)</strong>, 2024 <br>
        <a href="https://github.com/kuofenggao/verbose_images">[code]</a>
        <a href="https://arxiv.org/abs/2401.11170">[arxiv]</a>
    </li>
</ul>

<h3>2023</h3>
<ul>
	<li>
        <a href='https://arxiv.org/abs/2303.12993'>Backdoor Defense via Adaptively Splitting Poisoned Dataset</a> <br>
        <strong><u>Kuofeng Gao</u></strong>, Yang Bai, Jindong Gu, Yong Yang, Shu-Tao Xia <br>
        IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2023 <br>
        <a href="https://github.com/kuofenggao/asd">[code]</a>
        <a href="https://arxiv.org/abs/2303.12993">[arxiv]</a>
    </li>
	<li>
        <a href='https://ieeexplore.ieee.org/document/10319836'>Imperceptible and Robust Backdoor Attack in 3D Point Cloud</a> <br>
        <strong><u>Kuofeng Gao</u></strong>, Jiawang Bai, Baoyuan Wu, Mengxi Ya, Shu-Tao Xia <br>
        IEEE Transactions on Information Forensics and Security <strong>(TIFS)</strong>, 2023 <br>
        <a href="https://github.com/KuofengGao/IRBA">[code]</a>
        <a href="https://ieeexplore.ieee.org/document/10319836">[arxiv]</a>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2109.08868'>Backdoor Attack on Hash-based Image Retrieval via Clean-label Data Poisoning</a> <br>
        <strong><u>Kuofeng Gao</u></strong>, Jiawang Bai, Bin Chen, Dongxian Wu, Shu-Tao Xia <br>
        British Machine Vision Conference <strong>(BMVC)</strong>, 2023 <br>
        <a href="https://github.com/KuofengGao/CIBA">[code]</a>
        <a href="https://arxiv.org/abs/2109.08868">[arxiv]</a>
    </li>
</ul>

<h3>2022</h3>
<ul>
	<li>
        <a href='https://www.sciencedirect.com/science/article/pii/S0031320322003156'>Practical Protection against Video Data Leakage via Universal Adversarial Head</a> <br>
        Jiawang Bai, Bin Chen, <strong><u>Kuofeng Gao</u></strong>, Xuan Wang, Shu-Tao Xia <br>
        Pattern Recognition <strong>(PR)</strong>, 2022 <br>
    </li>
	<li>
        <a href='https://arxiv.org/abs/2207.13417'>Hardly Perceptible Trojan Attack against Neural Networks with Bit Flips</a> <br>
        Jiawang Bai, <strong><u>Kuofeng Gao</u></strong>, Dihong Gong, Shu-Tao Xia, Zhifeng Li, Wei Liu <br>
        European Conference on Computer Vision <strong>(ECCV)</strong>, 2022 <br>
        <a href="https://github.com/jiawangbai/HPT">[code]</a>
        <a href="https://arxiv.org/abs/2207.13417">[arxiv]</a>
    </li>
</ul>



<h2>Honors &amp; Awards</h2>
<ul>
    <li>
        <strong>Excellent Science & Technology Papers (1/100)</strong>, Shenzhen Association for Science and Technology, 2024
    </li>
    <li>
        <strong>First Prize Scholarship (Top 20%)</strong>, SIGS, Tsinghua University, 2024
    </li>
    <li>
        <strong>Future Scholar Ph.D. Scholarship (Top 1%)</strong>, Tsinghua University, 2024
    </li>
    <li>
        <strong>First Prize Scholarship (Top 10%)</strong>, Tsinghua University, 2024
    </li>
    <li>
        <strong>Tencent Rhino-Bird Elite Talent (Top 50+ in China)</strong>, Tencent, 2023
    </li>
    <li>
        <strong>Finalist (Top 1%)</strong>, Mathematical Contest In Modeling / Interdisciplinary Contest In Modeling, 2020
    </li>
    <li>
        <strong>LuoGe-TianYou Scholarship (Top 1%)</strong>, Wuhan University, 2020
    </li>
    <li>
        <strong>Liu DaoYu Scholarship (Top 1%)</strong>, Wuhan University, 2020
    </li>
    <li>
        <strong>LuoJia Excellent Exchange Scholarship (Top 10%)</strong>, Wuhan University, 2019
    </li>
    <li>
        <strong>National Scholarship (Top 0.2%)</strong>, Ministry of Education of China, 2019
    </li>
</ul>


<h2>Services</h2>
	
I was a reviewer / PC member of conferences: <br>
<ul>
    <li>
        IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong> 2024-2025<br>
    </li>
    <li>
        European Conference on Computer Vision <strong>(ECCV)</strong> 2024<br>
    </li>
    <li>
        International Conference on Computer Vision <strong>(ICCV)</strong> 2025
    </li>
    <li>
        ACM Multimedia <strong>(MM)</strong> 2024-2025<br>
    </li>
    <li>
        Neural Information Processing Systems <strong>(NeurIPS)</strong> 2024-2025<br>
    </li>
    <li>
        Neural Information Processing Systems Datasets and Benchmarks Track <strong>(NeurIPS D&B)</strong> 2024<br>
    </li>
    <li>
        International Conference on Learning Representations <strong>(ICLR)</strong> 2025<br>
    </li>
    <li>
        International Conference on Machine Learning <strong>(ICML)</strong> 2025<br>
    </li>
    <li>
        Artificial Intelligence and Statistics <strong>(AISTATS)</strong> 2025<br>
    </li>
</ul>
<br>

I was a reviewer of journals: <br>
<ul>
    <li>
        IEEE Transactions on Information Forensics & Security <strong>(TIFS)</strong><br>
    </li>
    <li>
        IEEE Transactions on Dependable and Secure Computing <strong>(TDSC)</strong><br>
    </li>
    <li>
        IEEE Transactions on Multimedia <strong>(TMM)</strong><br>
    </li>
    <li>
        IEEE Transactions on Circuits and Systems for Video Technology <strong>(TCSVT)</strong><br>
    </li>
    <li>
        Pattern Recognition <strong>(PR)</strong><br>
    </li>
</ul>

<h2>Teaching</h2>
<p>
2024 Fall, TA in <strong>Applied Information Theory</strong>, instructed by Prof. Shu-Tao Xia


<div id="footer">
	<div id="footer-text"></div>
</div>
&copy 2025 Kuofeng Gao
</body></html>
